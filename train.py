import torch
import torch.utils.data
import torch.backends.cudnn as cudnn
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter
from tqdm import tqdm

import os
import json
import valid
from utils import utils
from utils import sam
from utils import option
from data import dataset
from model import HTR_VT
from functools import partial

# Wandb for experiment tracking
try:
    import wandb

    WANDB_AVAILABLE = True
except ImportError:
    WANDB_AVAILABLE = False
    print("Warning: wandb not installed. Install with: pip install wandb")


# ============================================================
# Loss Computation Functions
# ============================================================


def compute_ctc_loss(preds, criterion, text, length, batch_size):
    """è®¡ç®— CTC Loss"""
    preds = preds.float()  # CTC Loss è¦æ±‚ float32
    preds_size = torch.IntTensor([preds.size(1)] * batch_size).cuda()
    preds = preds.permute(1, 0, 2).log_softmax(2)

    torch.backends.cudnn.enabled = False
    loss = criterion(preds, text.cuda(), preds_size, length.cuda()).mean()
    torch.backends.cudnn.enabled = True
    return loss


def compute_attn_loss(logits, targets, ignore_index=0):
    """
    è®¡ç®— Attention åˆ†æ”¯çš„ CrossEntropy Loss

    Args:
        logits: (B, T, C) - æ¨¡å‹è¾“å‡º
        targets: (B, T) - ç›®æ ‡æ ‡ç­¾ (PAD_IDX=0 will be ignored)
        ignore_index: å¿½ç•¥çš„æ ‡ç­¾ç´¢å¼• (PAD)
    """
    B, T, C = logits.shape
    logits_flat = logits.view(-1, C)  # (B*T, C)
    targets_flat = targets.view(-1)  # (B*T,)
    loss = F.cross_entropy(logits_flat, targets_flat, ignore_index=ignore_index)
    return loss


def compute_hybrid_loss(
    args,
    model,
    image,
    batch_size,
    ctc_criterion,
    ctc_text,
    ctc_length,
    attn_targets=None,
    use_language_model=True,
    lambda_ctc=1.0,
    lambda_attn=1.0,
    lambda_lang=1.0,
):
    """
    è®¡ç®—æ··åˆæŸå¤± (CTC + Attention)

    Loss = Î»_ctc * L_CTC + Î»_attn * L_CE(vis_logits) + Î»_lang * L_CE(fused_logits)

    Args:
        args: è®­ç»ƒå‚æ•°
        model: HTR-VT æ¨¡å‹
        image: è¾“å…¥å›¾åƒ (B, 1, H, W)
        batch_size: æ‰¹æ¬¡å¤§å°
        ctc_criterion: CTC Loss å‡½æ•°
        ctc_text: CTC ç¼–ç çš„æ–‡æœ¬
        ctc_length: CTC æ–‡æœ¬é•¿åº¦
        attn_targets: Attention åˆ†æ”¯çš„ç›®æ ‡ (B, T)
        use_language_model: æ˜¯å¦ä½¿ç”¨è¯­è¨€æ¨¡å‹
        lambda_ctc: CTC æŸå¤±æƒé‡
        lambda_attn: Visual Attention æŸå¤±æƒé‡
        lambda_lang: Language Model æŸå¤±æƒé‡

    Returns:
        total_loss: æ€»æŸå¤±
        loss_dict: å„é¡¹æŸå¤±çš„å­—å…¸
    """
    # Forward pass
    outputs = model(image, args.mask_ratio, args.max_span_length, use_masking=True)

    if use_language_model and isinstance(outputs, dict):
        # Hybrid mode: CTC + Attention
        ctc_logits = outputs["ctc"]  # (B, 128, C)
        attn_logits = outputs["attn"]  # (B, T, C) - fused output
        vis_logits = outputs["vis_logits"]  # (B, T, C)
        lang_logits = outputs["lang_logits"]  # (B, T, C)

        # CTC Loss
        loss_ctc = compute_ctc_loss(
            ctc_logits, ctc_criterion, ctc_text, ctc_length, batch_size
        )

        # Attention Loss (on fused output)
        loss_attn = compute_attn_loss(attn_logits, attn_targets, ignore_index=0)

        # Visual Attention Loss (auxiliary)
        loss_vis = compute_attn_loss(vis_logits, attn_targets, ignore_index=0)

        # Total loss
        total_loss = (
            lambda_ctc * loss_ctc + lambda_attn * loss_vis + lambda_lang * loss_attn
        )

        loss_dict = {
            "ctc": loss_ctc.item(),
            "attn": loss_attn.item(),
            "vis": loss_vis.item(),
            "total": total_loss.item(),
        }

        return total_loss, loss_dict
    else:
        # CTC only mode (backward compatible)
        preds = outputs if not isinstance(outputs, dict) else outputs["ctc"]
        loss = compute_ctc_loss(preds, ctc_criterion, ctc_text, ctc_length, batch_size)
        return loss, {"ctc": loss.item(), "total": loss.item()}


def main():
    args = option.get_args_parser()
    torch.manual_seed(args.seed)

    args.save_dir = os.path.join(args.out_dir, args.exp_name)
    os.makedirs(args.save_dir, exist_ok=True)

    logger = utils.get_logger(args.save_dir)
    logger.info(json.dumps(vars(args), indent=4, sort_keys=True))

    # Initialize wandb if enabled
    if args.use_wandb and WANDB_AVAILABLE:
        wandb.init(
            project="HTR-Mask",
            name=args.exp_name,
            config=vars(args),
            dir=args.save_dir,
        )
        logger.info("Wandb initialized successfully!")
    elif args.use_wandb and not WANDB_AVAILABLE:
        logger.warning("Wandb requested but not available. Using tensorboard only.")

    writer = SummaryWriter(args.save_dir)

    # ============================================================
    # Model Configuration
    # ============================================================
    max_length = getattr(args, "max_length", 26)  # é»˜è®¤æœ€å¤§åºåˆ—é•¿åº¦
    use_language_model = getattr(args, "use_language_model", True)  # æ˜¯å¦ä½¿ç”¨è¯­è¨€æ¨¡å‹

    model = HTR_VT.create_model(
        nb_cls=args.nb_cls,
        img_size=args.img_size[::-1],
        max_length=max_length,
        use_language_model=use_language_model,
    )

    total_param = sum(p.numel() for p in model.parameters())
    logger.info(f"Total parameters: {total_param:,}")
    logger.info(f"Language Model: {'Enabled' if use_language_model else 'Disabled'}")
    logger.info(f"Max sequence length: {max_length}")

    model.train()
    model = model.cuda()
    model_ema = utils.ModelEma(model, args.ema_decay)
    model.zero_grad()

    logger.info("Loading train loader...")
    train_dataset = dataset.myLoadDS(
        args.train_data_list, args.data_path, args.img_size
    )
    train_loader = torch.utils.data.DataLoader(
        train_dataset,
        batch_size=args.train_bs,
        shuffle=True,
        pin_memory=True,
        num_workers=args.num_workers,
        collate_fn=partial(dataset.SameTrCollate, args=args),
    )
    train_iter = dataset.cycle_data(train_loader)

    logger.info("Loading val loader...")
    val_dataset = dataset.myLoadDS(
        args.val_data_list, args.data_path, args.img_size, ralph=train_dataset.ralph
    )
    val_loader = torch.utils.data.DataLoader(
        val_dataset,
        batch_size=args.val_bs,
        shuffle=False,
        pin_memory=True,
        num_workers=args.num_workers,
    )

    optimizer = sam.SAM(
        model.parameters(),
        torch.optim.AdamW,
        lr=1e-7,
        betas=(0.9, 0.99),
        weight_decay=args.weight_decay,
    )

    # ============================================================
    # Loss Functions & Converters
    # ============================================================
    # CTC Loss & Converter
    ctc_criterion = torch.nn.CTCLoss(reduction="none", zero_infinity=True)
    ctc_converter = utils.CTCLabelConverter(train_dataset.ralph.values())

    # Attention Loss & Converter (for language model branch)
    attn_converter = None
    if use_language_model:
        attn_converter = utils.AttnLabelConverter(
            train_dataset.ralph.values(), max_length=max_length
        )
        logger.info(
            f"AttnLabelConverter initialized with {attn_converter.num_classes} classes"
        )

    best_cer, best_wer = 1e6, 1e6
    train_loss = 0.0
    train_loss_ctc = 0.0
    train_loss_attn = 0.0

    # Loss weights (å¯ä»¥é€šè¿‡ args é…ç½®)
    lambda_ctc = getattr(args, "lambda_ctc", 1.0)
    lambda_attn = getattr(args, "lambda_attn", 1.0)
    lambda_lang = getattr(args, "lambda_lang", 1.0)

    # ============================================================
    # Auto-Resume Logic (ä¼˜å…ˆä» latest.pth æ¢å¤)
    # ============================================================
    start_iter = 1
    resume_path = os.path.join(args.save_dir, "latest.pth")
    best_cer_path = os.path.join(args.save_dir, "best_CER.pth")

    if os.path.exists(resume_path):
        # ä¼˜å…ˆä» latest.pth æ¢å¤ï¼ˆåŒ…å«å®Œæ•´çš„è®­ç»ƒçŠ¶æ€ï¼‰
        logger.info(f"ğŸš€ Resuming from latest checkpoint: {resume_path}")
        checkpoint = torch.load(resume_path, map_location="cuda")

        # Load model weights
        try:
            model.load_state_dict(checkpoint["model"], strict=True)
            logger.info("Loaded model weights from checkpoint (strict)")
        except RuntimeError as e:
            logger.warning(f"Strict loading failed: {e}")
            model.load_state_dict(checkpoint["model"], strict=False)
            logger.info("Loaded model weights from checkpoint (non-strict)")

        # Load EMA weights
        if "state_dict_ema" in checkpoint:
            try:
                model_ema.ema.load_state_dict(checkpoint["state_dict_ema"], strict=True)
                logger.info("Loaded EMA weights from checkpoint (strict)")
            except RuntimeError:
                model_ema.ema.load_state_dict(
                    checkpoint["state_dict_ema"], strict=False
                )
                logger.info("Loaded EMA weights from checkpoint (non-strict)")

        # Load optimizer state (å®Œæ•´æ¢å¤è®­ç»ƒçŠ¶æ€)
        if "optimizer" in checkpoint:
            optimizer.load_state_dict(checkpoint["optimizer"])
            logger.info("Loaded optimizer state from checkpoint")

        # Restore training progress
        start_iter = checkpoint.get("nb_iter", 0) + 1
        best_cer = checkpoint.get("best_cer", 1e6)
        best_wer = checkpoint.get("best_wer", 1e6)

        logger.info(
            f"âœ… Resumed from Iter {start_iter}, Best CER: {best_cer:.4f}, Best WER: {best_wer:.4f}"
        )

        del checkpoint
        torch.cuda.empty_cache()

    elif os.path.exists(best_cer_path):
        # Fallback: ä» best_CER.pth æ¢å¤ï¼ˆåªæ¢å¤æ¨¡å‹æƒé‡ï¼‰
        logger.info(
            f"Found best checkpoint at {best_cer_path}, loading weights only..."
        )
        checkpoint = torch.load(best_cer_path, map_location="cuda")

        try:
            model.load_state_dict(checkpoint["model"], strict=True)
            logger.info("Loaded model weights from best_CER.pth (strict)")
        except RuntimeError as e:
            logger.warning(f"Strict loading failed: {e}")
            model.load_state_dict(checkpoint["model"], strict=False)
            logger.info("Loaded model weights from best_CER.pth (non-strict)")

        if "state_dict_ema" in checkpoint:
            try:
                model_ema.ema.load_state_dict(checkpoint["state_dict_ema"], strict=True)
            except RuntimeError:
                model_ema.ema.load_state_dict(
                    checkpoint["state_dict_ema"], strict=False
                )
            logger.info("Loaded EMA weights from best_CER.pth")

        # NOTE: ä» best_CER.pth æ¢å¤æ—¶ä¸åŠ è½½ optimizerï¼Œä»å¤´å¼€å§‹ä¼˜åŒ–
        logger.info(
            "âš ï¸ Starting from iter 1 (optimizer state not loaded from best_CER.pth)"
        )

        del checkpoint
        torch.cuda.empty_cache()
    else:
        logger.info("No checkpoint found, starting training from scratch")

    #### ---- train & eval ---- ####

    # Create progress bar
    pbar = tqdm(range(start_iter, args.total_iter), desc="Training", unit="iter")
    pbar.set_description(f"Training (from iter {start_iter})")

    for nb_iter in pbar:
        optimizer, current_lr = utils.update_lr_cos(
            nb_iter, args.warm_up_iter, args.total_iter, args.max_lr, optimizer
        )

        optimizer.zero_grad()
        batch = next(train_iter)
        image = batch[0].cuda()
        batch_size = image.size(0)

        # Encode labels for both branches
        ctc_text, ctc_length = ctc_converter.encode(batch[1])
        attn_targets = None
        if use_language_model and attn_converter is not None:
            attn_targets, attn_lengths = attn_converter.encode(batch[1])

        # ============================================================
        # First forward-backward pass (SAM Step 1)
        # ============================================================
        loss, loss_dict = compute_hybrid_loss(
            args,
            model,
            image,
            batch_size,
            ctc_criterion,
            ctc_text,
            ctc_length,
            attn_targets=attn_targets,
            use_language_model=use_language_model,
            lambda_ctc=lambda_ctc,
            lambda_attn=lambda_attn,
            lambda_lang=lambda_lang,
        )

        # === [Safety] NaN/Inf Loss Protection ===
        if torch.isnan(loss) or torch.isinf(loss):
            logger.warning(
                f"âš ï¸ Warning: NaN/Inf loss detected at Iter {nb_iter}. Skipping batch to prevent crash."
            )
            optimizer.zero_grad()
            continue
        # ========================================

        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping
        optimizer.first_step(zero_grad=True)

        # ============================================================
        # Second forward-backward pass (SAM Step 2)
        # ============================================================
        loss2, _ = compute_hybrid_loss(
            args,
            model,
            image,
            batch_size,
            ctc_criterion,
            ctc_text,
            ctc_length,
            attn_targets=attn_targets,
            use_language_model=use_language_model,
            lambda_ctc=lambda_ctc,
            lambda_attn=lambda_attn,
            lambda_lang=lambda_lang,
        )
        loss2.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # Gradient clipping
        optimizer.second_step(zero_grad=True)

        model.zero_grad()
        model_ema.update(model, num_updates=nb_iter / 2)

        # Accumulate losses
        train_loss += loss_dict["total"]
        train_loss_ctc += loss_dict.get("ctc", 0)
        train_loss_attn += loss_dict.get("attn", 0)

        # Update progress bar
        pbar.set_postfix(
            {
                "loss": f"{loss_dict['total']:.4f}",
                "ctc": f"{loss_dict.get('ctc', 0):.3f}",
                "attn": f"{loss_dict.get('attn', 0):.3f}",
                "lr": f"{current_lr:.6f}",
                "best_cer": f"{best_cer:.4f}" if best_cer < 1e6 else "N/A",
            }
        )

        if nb_iter % args.print_iter == 0:
            train_loss_avg = train_loss / args.print_iter
            train_loss_ctc_avg = train_loss_ctc / args.print_iter
            train_loss_attn_avg = train_loss_attn / args.print_iter

            logger.info(
                f"Iter : {nb_iter} \t LR : {current_lr:0.5f} \t "
                f"Total : {train_loss_avg:0.4f} \t CTC : {train_loss_ctc_avg:0.4f} \t "
                f"Attn : {train_loss_attn_avg:0.4f}"
            )

            writer.add_scalar("./Train/lr", current_lr, nb_iter)
            writer.add_scalar("./Train/train_loss", train_loss_avg, nb_iter)
            writer.add_scalar("./Train/loss_ctc", train_loss_ctc_avg, nb_iter)
            writer.add_scalar("./Train/loss_attn", train_loss_attn_avg, nb_iter)

            # Log to wandb
            if args.use_wandb and WANDB_AVAILABLE:
                wandb.log(
                    {
                        "train/loss": train_loss_avg,
                        "train/loss_ctc": train_loss_ctc_avg,
                        "train/loss_attn": train_loss_attn_avg,
                        "train/lr": current_lr,
                        "iter": nb_iter,
                    }
                )

            train_loss = 0.0
            train_loss_ctc = 0.0
            train_loss_attn = 0.0

        # === [Safety] Save Latest Checkpoint Periodically ===
        save_latest_interval = getattr(args, "save_latest_interval", 1000)
        if nb_iter % save_latest_interval == 0:
            checkpoint = {
                "model": model.state_dict(),
                "state_dict_ema": model_ema.ema.state_dict(),
                "optimizer": optimizer.state_dict(),
                "nb_iter": nb_iter,
                "best_cer": best_cer,
                "best_wer": best_wer,
            }
            latest_path = os.path.join(args.save_dir, "latest.pth")
            torch.save(checkpoint, latest_path)
            logger.info(f"ğŸ’¾ Saved latest checkpoint to {latest_path} (iter {nb_iter})")
        # ====================================================

        if nb_iter % args.eval_iter == 0:
            model.eval()
            with torch.no_grad():
                val_loss, val_cer, val_wer, preds, labels = valid.validation(
                    model_ema.ema, ctc_criterion, val_loader, ctc_converter
                )

                if val_cer < best_cer:
                    logger.info(f"CER improved from {best_cer:.4f} to {val_cer:.4f}!!!")
                    best_cer = val_cer
                    checkpoint = {
                        "model": model.state_dict(),
                        "state_dict_ema": model_ema.ema.state_dict(),
                        "optimizer": optimizer.state_dict(),
                    }
                    torch.save(checkpoint, os.path.join(args.save_dir, "best_CER.pth"))

                if val_wer < best_wer:
                    logger.info(f"WER improved from {best_wer:.4f} to {val_wer:.4f}!!!")
                    best_wer = val_wer
                    checkpoint = {
                        "model": model.state_dict(),
                        "state_dict_ema": model_ema.ema.state_dict(),
                        "optimizer": optimizer.state_dict(),
                    }
                    torch.save(checkpoint, os.path.join(args.save_dir, "best_WER.pth"))

                logger.info(
                    f"Val. loss : {val_loss:0.3f} \t CER : {val_cer:0.4f} \t WER : {val_wer:0.4f}"
                )

                writer.add_scalar("./VAL/CER", val_cer, nb_iter)
                writer.add_scalar("./VAL/WER", val_wer, nb_iter)
                writer.add_scalar("./VAL/bestCER", best_cer, nb_iter)
                writer.add_scalar("./VAL/bestWER", best_wer, nb_iter)
                writer.add_scalar("./VAL/val_loss", val_loss, nb_iter)

                # Log validation metrics to wandb
                if args.use_wandb and WANDB_AVAILABLE:
                    wandb.log(
                        {
                            "val/loss": val_loss,
                            "val/cer": val_cer,
                            "val/wer": val_wer,
                            "val/best_cer": best_cer,
                            "val/best_wer": best_wer,
                            "iter": nb_iter,
                        }
                    )

                model.train()

    # Close progress bar
    pbar.close()

    # Finish wandb run
    if args.use_wandb and WANDB_AVAILABLE:
        wandb.finish()
        logger.info("Wandb run finished.")


if __name__ == "__main__":
    main()
